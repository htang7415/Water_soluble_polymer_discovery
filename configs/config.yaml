# Inverse Polymer Design (water-soluble focus)
# Active workflow:
# Step 0: data prep
# Step 1: backbone training
# Step 2: sampling and generative evaluation
# Step 3: chi_target learning from labeled chi(T,phi) dataset
# Step 4: physics-guided chi(T,phi) model training (+ Optuna)
# Step 5: water-soluble inverse design
# Step 6: polymer-family class + water-soluble inverse design

paths:
  data_dir: "Data"
  polymer_file: "Data/Polymer/SMiPoly_polymers.gz"
  property_dir: "Data/Property"
  results_dir: "results"

data:
  random_seed: 42
  train_fraction: 1.0
  unlabeled_train_ratio: 0.95
  unlabeled_val_ratio: 0.05
  property_train_ratio: 0.8
  property_val_ratio: 0.1
  property_test_ratio: 0.1

tokenizer:
  special_tokens:
    pad: "[PAD]"
    mask: "[MASK]"
    bos: "[BOS]"
    eos: "[EOS]"
    unk: "[UNK]"
  max_length: 128

# Default architecture (matches small preset when model_size is not specified)
backbone:
  hidden_size: 384
  num_layers: 6
  num_heads: 6
  ffn_hidden_size: 1536
  dropout: 0.1
  max_position_embeddings: 256

# Presets used by --model_size in Step 1/2/3/4/5/6
model_sizes:
  small:
    hidden_size: 384
    num_layers: 6
    num_heads: 6
    ffn_hidden_size: 1536
    dropout: 0.1
    max_position_embeddings: 256
    max_steps: 300000
    warmup_steps: 1000
    batch_size: 128
    gradient_accumulation_steps: 4
    learning_rate: 3.0e-4
  medium:
    hidden_size: 640
    num_layers: 10
    num_heads: 10
    ffn_hidden_size: 2560
    dropout: 0.1
    max_position_embeddings: 256
    max_steps: 300000
    warmup_steps: 2000
    batch_size: 128
    gradient_accumulation_steps: 4
    learning_rate: 3.0e-4
  large:
    hidden_size: 960
    num_layers: 14
    num_heads: 12
    ffn_hidden_size: 3840
    dropout: 0.1
    max_position_embeddings: 256
    max_steps: 300000
    warmup_steps: 3000
    batch_size: 128
    gradient_accumulation_steps: 8
    learning_rate: 1.0e-4
  xl:
    hidden_size: 1280
    num_layers: 20
    num_heads: 16
    ffn_hidden_size: 5120
    dropout: 0.1
    max_position_embeddings: 256
    max_steps: 300000
    warmup_steps: 4000
    batch_size: 64
    gradient_accumulation_steps: 16
    learning_rate: 1.0e-4

diffusion:
  num_steps: 50
  beta_min: 0.05
  beta_max: 0.95

training_backbone:
  batch_size: 128
  learning_rate: 3.0e-4
  weight_decay: 0.01
  warmup_steps: 1000
  max_steps: 300000
  gradient_clip_norm: 1.0
  eval_every: 1000
  save_every: 100000
  num_epochs: 50

# Kept for embedding timestep and backward compatibility.
training_property:
  batch_size: 128
  learning_rate: 1.0e-3
  weight_decay: 0.01
  num_epochs: 500
  patience: 30
  freeze_backbone: true
  finetune_last_layers: 6
  default_timestep: 1

# Step 3-6 chi workflow config
chi_training:
  dataset_path: "Data/chi/_50_polymers_T_phi.csv"
  split_mode: "polymer"  # polymer | random

  # Step 3: chi_target learning
  target_objective: "balanced_accuracy"  # balanced_accuracy | youden_j | f1 | accuracy
  target_bootstrap_repeats: 800

  # Step 4: chi(T,phi) model training
  train_ratio: 1.0
  val_ratio: 0.1
  test_ratio: 0.1
  batch_size: 128
  num_epochs: 500
  patience: 20
  learning_rate: 1.0e-3
  weight_decay: 1.0e-5
  lambda_bce: 0.1
  hidden_sizes: [256, 128]
  dropout: 0.1

  # Step 4 Optuna
  tune: true
  n_trials: 50
  tuning_epochs: 120
  tuning_patience: 20
  optuna_search_space:
    # If list has exactly 2 values, it is treated as a continuous range [min, max].
    # If list has >2 values, it is treated as categorical choices.
    num_layers: [2, 3, 4, 5]
    hidden_units: [64, 128, 256, 512, 1024]
    dropout: [0.0, 0.1, 0.2, 0.3]
    learning_rate: [1.0e-4, 5.0e-3]
    learning_rate_log: true
    weight_decay: [1.0e-7, 1.0e-3]
    weight_decay_log: true
    lambda_bce: [0.01, 0.05, 0.1, 0.2, 0.5]
    batch_size: [8, 16, 32, 64, 128, 256]

  # Step 4/5/6 embedding extraction
  embedding_timestep: 1
  embedding_batch_size: 128

  # Step 5/6 inverse-design scoring
  epsilon: 0.05
  class_weight: 0.25
  polymer_class_weight: 0.50
  candidate_source: "novel"
  property_rule: "upper_bound"
  coverage_topk: 5
  target_polymer_class: "all"

checkpointing:
  save_best_only: true
  save_last: false
  save_periodic: false

optimization:
  use_amp: true
  compile_model: true
  compile_mode: "default"
  gradient_accumulation_steps: 4
  num_workers: 4
  pin_memory: true
  cudnn_benchmark: true
  prefetch_factor: 2
  cache_tokenization: true

sampling:
  num_samples: 10000
  batch_size: 256
  temperature: 0.9
  top_k: null
  top_p: null
  target_stars: 2
  use_constraints: true

# SMARTS-like family tags used in Step 6.
polymer_classes:
  polyimide: "[#6](=O)-[#7]-[#6](=O)"
  polyester: "[#6](=O)-[#8]-[#6]"
  polyamide: "[#6](=O)-[#7]-[#6]"
  polyurethane: "[#8]-[#6](=O)-[#7]"
  polyether: "[#6]-[#8]-[#6]"

plotting:
  figure_size: [4.5, 4.5]
  font_size: 12
  dpi: 600
