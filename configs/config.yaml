# Inverse Polymer Design (water-soluble focus)
# Active workflow:
# Step 0: data prep
# Step 1: backbone training
# Step 2: sampling and generative evaluation
# Step 3: chi_target learning from labeled chi(T,phi) dataset
# Step 4: physics-guided chi(T,phi) model training (+ Optuna)
# Step 5: water-soluble inverse design
# Step 6: polymer-family class + water-soluble inverse design

paths:
  data_dir: "Data"
  polymer_file: "Data/Polymer/SMiPoly_polymers.gz"
  property_dir: "Data/Property"
  results_dir: "results"

data:
  random_seed: 42
  train_fraction: 1.0
  unlabeled_train_ratio: 0.95
  unlabeled_val_ratio: 0.05
  property_train_ratio: 0.8
  property_val_ratio: 0.1
  property_test_ratio: 0.1

tokenizer:
  special_tokens:
    pad: "[PAD]"
    mask: "[MASK]"
    bos: "[BOS]"
    eos: "[EOS]"
    unk: "[UNK]"
  max_length: 128

# Default architecture (matches small preset when model_size is not specified)
backbone:
  hidden_size: 384
  num_layers: 6
  num_heads: 6
  ffn_hidden_size: 1536
  dropout: 0.1
  max_position_embeddings: 256

# Presets used by --model_size in Step 1/2/3/4/5/6
model_sizes:
  small:
    hidden_size: 384
    num_layers: 6
    num_heads: 6
    ffn_hidden_size: 1536
    dropout: 0.1
    max_position_embeddings: 256
    max_steps: 300000
    warmup_steps: 1000
    batch_size: 128
    gradient_accumulation_steps: 4
    learning_rate: 3.0e-4
  medium:
    hidden_size: 640
    num_layers: 10
    num_heads: 10
    ffn_hidden_size: 2560
    dropout: 0.1
    max_position_embeddings: 256
    max_steps: 300000
    warmup_steps: 2000
    batch_size: 128
    gradient_accumulation_steps: 4
    learning_rate: 3.0e-4
  large:
    hidden_size: 960
    num_layers: 14
    num_heads: 12
    ffn_hidden_size: 3840
    dropout: 0.1
    max_position_embeddings: 256
    max_steps: 300000
    warmup_steps: 3000
    batch_size: 128
    gradient_accumulation_steps: 8
    learning_rate: 1.0e-4
  xl:
    hidden_size: 1280
    num_layers: 20
    num_heads: 16
    ffn_hidden_size: 5120
    dropout: 0.1
    max_position_embeddings: 256
    max_steps: 300000
    warmup_steps: 4000
    batch_size: 64
    gradient_accumulation_steps: 16
    learning_rate: 1.0e-4

diffusion:
  num_steps: 50
  beta_min: 0.05
  beta_max: 0.95

training_backbone:
  batch_size: 128
  learning_rate: 3.0e-4
  weight_decay: 0.01
  warmup_steps: 1000
  max_steps: 300000
  gradient_clip_norm: 1.0
  eval_every: 1000
  save_every: 100000
  num_epochs: 50

# Kept for embedding timestep and backward compatibility.
training_property:
  batch_size: 128
  learning_rate: 1.0e-3
  weight_decay: 0.01
  num_epochs: 500
  patience: 30
  freeze_backbone: true
  finetune_last_layers: 6  # legacy property-head setting; Step 4 uses chi_training.finetune_last_layers (fallback here if missing)
  default_timestep: 1

# Step 3-6 chi workflow config (per-step structure)
chi_training:
  shared:
    dataset_path: "Data/chi/_50_polymers_T_phi.csv"  # labeled chi(T,phi) dataset used in Step 3 and Step4_1
    split_mode: "polymer"  # data split mode: polymer (hold out polymers) | random (row-wise random)
    split:
      train_ratio: 0.70  # train+val=84% dev pool for CV tuning; remaining 16% held-out test
      val_ratio: 0.14
      test_ratio: 0.16
    embedding:
      timestep: 1  # diffusion timestep used for embedding extraction
      batch_size: 128  # batch size for embedding extraction

  step3_target_learning:
    target_objective: "balanced_accuracy"  # threshold objective: balanced_accuracy | youden_j | f1 | accuracy
    target_bootstrap_repeats: 800  # bootstrap repeats for chi_target stability estimation

  # Step4_1: chi(T,phi) regression
  step4_1_regression:
    dataset_path: "Data/chi/_50_polymers_T_phi.csv"
    batch_size: 128
    num_epochs: 500
    patience: 20
    learning_rate: 1.0e-3
    weight_decay: 1.0e-5
    gradient_clip_norm: 1.0
    use_scheduler: true
    scheduler_min_lr: 1.0e-6
    hidden_sizes: [256, 512, 128]
    dropout: 0.1
    finetune_last_layers: 0  # integer in [0, num_layers(model_size)]; 0=freeze backbone

    tune: true
    n_trials: 200
    tuning_epochs: 100
    tuning_patience: 20
    tuning_objective: "val_r2"  # regression objective uses mean CV val_r2
    tuning_cv_folds: 6
    optuna_search_space:
      # If list has exactly 2 values, it is treated as a continuous range [min, max].
      # If list has >2 values, it is treated as categorical choices.
      # finetune_last_layers defaults to dynamic range [0, num_layers(model_size)] if omitted.
      num_layers: [2, 3, 4, 5]
      hidden_units: [64, 128, 256, 512, 1024]
      dropout: [0.0, 0.1, 0.2, 0.3]
      learning_rate: [1.0e-4, 5.0e-3]
      learning_rate_log: true
      weight_decay: [1.0e-7, 1.0e-3]
      weight_decay_log: true
      batch_size: [4, 8, 16, 32, 64, 128]

  # Step4_2: water-soluble classification
  step4_2_classification:
    dataset_path: "Data/water_solvent/water_solvent_polymers.csv"
    batch_size: 128
    num_epochs: 500
    patience: 20
    learning_rate: 1.0e-3
    weight_decay: 1.0e-5
    gradient_clip_norm: 1.0
    use_scheduler: true
    scheduler_min_lr: 1.0e-6
    hidden_sizes: [256, 512, 128]
    dropout: 0.1
    finetune_last_layers: 0  # integer in [0, num_layers(model_size)]; 0=freeze backbone

    tune: true
    n_trials: 200
    tuning_epochs: 100
    tuning_patience: 20
    tuning_cv_folds: 6
    optuna_search_space:
      # If list has exactly 2 values, it is treated as a continuous range [min, max].
      # If list has >2 values, it is treated as categorical choices.
      # finetune_last_layers defaults to dynamic range [0, num_layers(model_size)] if omitted.
      num_layers: [2, 3, 4, 5]
      hidden_units: [64, 128, 256, 512, 1024]
      dropout: [0.0, 0.1, 0.2, 0.3]
      learning_rate: [1.0e-4, 5.0e-3]
      learning_rate_log: true
      weight_decay: [1.0e-7, 1.0e-3]
      weight_decay_log: true
      batch_size: [4, 8, 16, 32, 64]

  # Step 5 inverse-design scoring
  step5_inverse_design:
    target_temperature: 293.15  # room temperature (K)
    target_phi: 0.2             # polymer fraction
    epsilon: 0.05  # tolerance for property hit when property_rule=band
    class_weight: 0.25  # penalty weight for low soluble confidence in ranking score
    target_polymer_count: 100  # final number of exported target polymers
    target_sa_max: 4.0  # SA upper bound for final target polymer export
    candidate_source: "novel"  # novel-only (Step 2 generated candidates)
    property_rule: "upper_bound"  # band | upper_bound | lower_bound
    coverage_topk: 5  # top-k used in coverage/frequency summaries

  # Step 6 inverse-design scoring (class + property)
  step6_class_inverse_design:
    target_temperature: 293.15  # room temperature (K)
    target_phi: 0.2             # polymer fraction
    epsilon: 0.05
    class_weight: 0.25
    polymer_class_weight: 0.50  # penalty weight for class mismatch in ranking score
    target_polymer_count: 100
    target_sa_max: 4.0
    candidate_source: "novel"  # novel-only (Step 2 generated candidates)
    property_rule: "upper_bound"
    coverage_topk: 5
    target_polymer_class: "polyamide"  # all | polyimide | polyester | polyamide | polyurethane | polyether

checkpointing:
  save_best_only: true
  save_last: false
  save_periodic: false

optimization:
  use_amp: true
  compile_model: true
  compile_mode: "default"
  gradient_accumulation_steps: 4
  num_workers: 4
  pin_memory: true
  cudnn_benchmark: true
  prefetch_factor: 2
  cache_tokenization: true

sampling:
  batch_size: 128  # raw generation batch size for Step 2 sampling
  temperature: 0.9  # sampling temperature (higher gives more diversity)
  top_k: null  # token filter: null disables, integer > 0 keeps top-k tokens
  top_p: null  # nucleus filter: null disables, value in (0, 1] enables
  target_stars: 2  # desired count of "*" tokens in generated polymers
  target_polymer_count: 100  # Step 2 target count after final filtering
  target_sa_max: 4.0  # SA cutoff for Step 2 target-polymers export
  valid_only: true  # if true, keep sampling rounds until target count is reached
  valid_only_require_target_stars: true  # in valid-only rounds enforce star_count == target_stars
  variable_length: false  # token-length mode: false uses train length profile, true uses range below
  variable_length_min_tokens: 12  # minimum token length when variable_length=true
  variable_length_max_tokens: 100  # maximum token length when variable_length=true
  variable_length_samples_per_length: 16  # number of samples drawn per length bucket
  valid_only_max_rounds: 25  # maximum valid-only resampling rounds
  valid_only_min_samples_per_round: 256  # minimum raw requests per valid-only round
  use_constraints: true  # enable constrained sampler checks (syntax/ring/star constraints)

# SMARTS-like family tags used in Step 6.
polymer_classes:
  polyimide: "[#6](=O)-[#7]-[#6](=O)"
  polyester: "[#6](=O)-[#8]-[#6]"
  polyamide: "[#6](=O)-[#7]-[#6]"
  polyurethane: "[#8]-[#6](=O)-[#7]"
  polyether: "[#6]-[#8]-[#6]"

plotting:
  figure_size: [4.5, 4.5]
  font_size: 12
  dpi: 600
